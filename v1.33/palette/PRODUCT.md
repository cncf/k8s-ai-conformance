# Spectro Cloud Palette â€” AI Conformance Report

## Platform Information

| | |
|:--|:--|
| **Vendor** | Spectro Cloud |
| **Platform** | Spectro Cloud Palette |
| **Platform Version** | 4.8.x |
| **Kubernetes Version** | v1.33 |
| **Website** | [https://www.spectrocloud.com/](https://www.spectrocloud.com/) |
| **Documentation** | [Link](https://docs.spectrocloud.com/) |

> Spectro Cloud Palette is a full-stack, declarative Kubernetes management platform for public cloud, private data centers and edge, with curated packs (CNIs, CSIs, operators) and policy-driven lifecycle automation.

---

## Compliance Summary

| Status | Count |
|:-------|:-----:|
| âœ… Implemented | 9 |
| **Total** | **9** |

### Requirements at a Glance

| Category | Requirement | Level | Status |
|:---------|:------------|:-----:|:------:|
| Accelerators | DRA Support | SHOULD | âœ… |
| Networking | AI Inference | MUST | âœ… |
| Scheduling & Orchestration | Gang Scheduling | MUST | âœ… |
| Scheduling & Orchestration | Cluster Autoscaling | MUST | âœ… |
| Scheduling & Orchestration | Pod Autoscaling | MUST | âœ… |
| Observability | Accelerator Metrics | MUST | âœ… |
| Observability | AI Service Metrics | MUST | âœ… |
| Security | Secure Accelerator Access | MUST | âœ… |
| Operator Support | Robust Controller | MUST | âœ… |

---

## Detailed Requirements

### ðŸš€ Accelerators

#### âœ… DRA Support

**Level:** ðŸŸ¡ SHOULD | **Status:** Implemented

> Support Dynamic Resource Allocation (DRA) APIs to enable more flexible and fine-grained resource requests beyond simple counts.

**Evidence:**

- [docs.spectrocloud.com/integrations/kubernetes/](https://docs.spectrocloud.com/integrations/kubernetes/)

**Notes:**

> PXK 1.33 clusters expose resource.k8s.io APIs; DRA can be enabled per cluster where required.

### ðŸŒ Networking

#### âœ… AI Inference

**Level:** ðŸ”´ MUST | **Status:** Implemented

> Support the Kubernetes Gateway API with an implementation for advanced traffic management for inference services, incl. weighted splits, header routing, and mesh integration.

**Evidence:**

- [docs.spectrocloud.com/integrations/](https://docs.spectrocloud.com/integrations/)
- [docs.spectrocloud.com/integrations/packs/?pack=kgateway](https://docs.spectrocloud.com/integrations/packs/?pack=kgateway)
- [docs.spectrocloud.com/integrations/kong/](https://docs.spectrocloud.com/integrations/kong/)

**Notes:**

> Palette installs/operates Gateway API-capable controllers out of the box (KGateway, Kong). Cilium supported as dataplane; service meshes (e.g., Istio) available via packs for optional integration.

### ðŸ“… Scheduling & Orchestration

#### âœ… Gang Scheduling

**Level:** ðŸ”´ MUST | **Status:** Implemented

> Platform must allow installation and successful operation of at least one gang scheduling solution (e.g., Kueue, Volcano).

**Evidence:**

- [docs.spectrocloud.com/integrations/packs/?pack=kai-schedu...](https://docs.spectrocloud.com/integrations/packs/?pack=kai-scheduler-ai)
- [docs.spectrocloud.com/registries-and-packs/](https://docs.spectrocloud.com/registries-and-packs/)

**Notes:**

> Validated via pack-based install of Kai; Palette supports CRDs/webhooks and CRD lifecycle.

#### âœ… Cluster Autoscaling

**Level:** ðŸ”´ MUST | **Status:** Implemented

> If autoscaler is provided, must scale node groups with specific accelerator types based on pending pods.

**Evidence:**

- [docs.spectrocloud.com/clusters/cluster-management/node-po...](https://docs.spectrocloud.com/clusters/cluster-management/node-pool/#worker-node-pool)
- [docs.spectrocloud.com/clusters/public-cloud/aws/configure...](https://docs.spectrocloud.com/clusters/public-cloud/aws/configure-karpenter-eks-clusters/)
- [docs.spectrocloud.com/integrations/aws-cluster-autoscaler/](https://docs.spectrocloud.com/integrations/aws-cluster-autoscaler/)

**Notes:**

> Palette supports the Kubernetes Cluster Autoscaler out of the box, and AWS Autoscaler and Karpenter through dedicated packs.

#### âœ… Pod Autoscaling

**Level:** ðŸ”´ MUST | **Status:** Implemented

> HPA must function for pods using accelerators, including custom metrics for AI/ML workloads.

**Evidence:**

- [docs.spectrocloud.com/integrations/prometheus-operator/](https://docs.spectrocloud.com/integrations/prometheus-operator/)
- [docs.spectrocloud.com/clusters/cluster-management/monitor...](https://docs.spectrocloud.com/clusters/cluster-management/monitoring/deploy-monitor-stack/)

**Notes:**

> HPA validated with GPU workloads. GPU utilization and memory metrics are exposed via DCGM exporter, collected by Prometheus Operator, and surfaced to HPA.

### ðŸ“Š Observability

#### âœ… Accelerator Metrics

**Level:** ðŸ”´ MUST | **Status:** Implemented

> Allow install/operation of at least one accelerator metrics solution with per-accelerator utilization and memory metrics; expose Prometheus/Otel endpoints.

**Evidence:**

- [docs.spectrocloud.com/integrations/packs/?pack=nvidia-gpu...](https://docs.spectrocloud.com/integrations/packs/?pack=nvidia-gpu-operator-ai)
- [docs.spectrocloud.com/integrations/](https://docs.spectrocloud.com/integrations/)
- [docs.spectrocloud.com/integrations/prometheus-operator/](https://docs.spectrocloud.com/integrations/prometheus-operator/)
- [docs.spectrocloud.com/clusters/cluster-management/monitor...](https://docs.spectrocloud.com/clusters/cluster-management/monitoring/)

**Notes:**

> Validated with NVIDIA GPU Operator (DCGM exporter) + Prometheus stack. Metrics include GPU utilization, memory usage, temperature, and power draw, all exposed via Prometheus-compatible /metrics endpoints.

#### âœ… AI Service Metrics

**Level:** ðŸ”´ MUST | **Status:** Implemented

> Provide a monitoring system capable of discovering/scraping Prometheus-format metrics from AI jobs and inference servers.

**Evidence:**

- [docs.spectrocloud.com/integrations/prometheus-operator/](https://docs.spectrocloud.com/integrations/prometheus-operator/)
- [docs.spectrocloud.com/clusters/cluster-management/monitor...](https://docs.spectrocloud.com/clusters/cluster-management/monitoring/deploy-monitor-stack/)
- [docs.spectrocloud.com/integrations/packs/?pack=nvidia-gpu...](https://docs.spectrocloud.com/integrations/packs/?pack=nvidia-gpu-operator-ai)

**Notes:**

> Prometheus Operator + ServiceMonitors scrape app endpoints; Grafana dashboards available via pack.

### ðŸ”’ Security

#### âœ… Secure Accelerator Access

**Level:** ðŸ”´ MUST | **Status:** Implemented

> Ensure accelerator access is isolated/mediated via device plugins or DRA and container runtime.

**Evidence:**

- [ai-cncf-conformance-secure-access.md](ai-cncf-conformance-secure-access.md)
- [docs.spectrocloud.com/integrations/packs/?pack=nvidia-gpu...](https://docs.spectrocloud.com/integrations/packs/?pack=nvidia-gpu-operator-ai)

**Notes:**

> Isolation via vendor device plugins (e.g., NVIDIA) + Kubernetes allocation; validated with per-pod device allocation tests.

### âš™ï¸ Operator Support

#### âœ… Robust Controller

**Level:** ðŸ”´ MUST | **Status:** Implemented

> Prove at least one complex AI operator with CRD (e.g., Ray, Kubeflow) installs and functions (pods, webhooks, CRD reconciliation).

**Evidence:**

- [docs.spectrocloud.com/integrations/packs/?pack=kuberay-op...](https://docs.spectrocloud.com/integrations/packs/?pack=kuberay-operator)
- [docs.spectrocloud.com/integrations/packs/?pack=kubeflow-t...](https://docs.spectrocloud.com/integrations/packs/?pack=kubeflow-training-operator)
- [docs.spectrocloud.com/integrations/packs/?pack=kubeflow-crds](https://docs.spectrocloud.com/integrations/packs/?pack=kubeflow-crds)

**Notes:**

> Palette supports deployment of complex AI operators including KubeRay and Kubeflow via packs. Operators install their CRDs, run admission webhooks, and reconcile custom resources as expected on PXK 1.33 clusters.

---

*Generated from PRODUCT.yaml*
